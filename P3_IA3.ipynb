{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbWJXqeZtJCeWPrraH17jZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93d4bb980f194c9ab907b9af379e34c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_317cc2d1b61542c7bcc0386dac07084e",
              "IPY_MODEL_6ecd5bad03a740939c69e42d62f7c10c",
              "IPY_MODEL_d91dc6980dd34bfc92d7046376847e82"
            ],
            "layout": "IPY_MODEL_918b3a416dc346b6af0ed4766a37ecf0"
          }
        },
        "317cc2d1b61542c7bcc0386dac07084e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4488ddabcc074e188585201dfafe912e",
            "placeholder": "​",
            "style": "IPY_MODEL_61ef3249605144a282ad6bdfbeedef69",
            "value": "Map: 100%"
          }
        },
        "6ecd5bad03a740939c69e42d62f7c10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3979bce8b645b8b612ba9c71124db0",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a43511eb5a1e4f0296f9dcd925da6ebd",
            "value": 1000
          }
        },
        "d91dc6980dd34bfc92d7046376847e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_884ab3696039412db512fca7c58da1c9",
            "placeholder": "​",
            "style": "IPY_MODEL_a4ea03018f4c47209c3dc74f60784b45",
            "value": " 1000/1000 [00:00&lt;00:00, 1952.20 examples/s]"
          }
        },
        "918b3a416dc346b6af0ed4766a37ecf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4488ddabcc074e188585201dfafe912e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ef3249605144a282ad6bdfbeedef69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c3979bce8b645b8b612ba9c71124db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43511eb5a1e4f0296f9dcd925da6ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "884ab3696039412db512fca7c58da1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4ea03018f4c47209c3dc74f60784b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyu990116/transformers_tutorials/blob/main/P3_IA3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMZ68CCiue3W"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/nlp\")\n",
        "!pip install datasets\n",
        "!pip install accelerate==0.22.0\n",
        "!pip install transformers==4.33.1\n",
        "!pip install peft==0.5.0\n",
        "from transformers import AutoTokenizer,AutoModelForCausalLM,DataCollatorForSeq2Seq,TrainingArguments,Trainer,pipeline\n",
        "from datasets import Dataset,load_dataset\n",
        "from peft import IA3Config, TaskType, get_peft_model, PeftModel\n",
        "ds = load_dataset(\"zhengr/alpaca-chinese-dataset\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Langboat/bloom-1b4-zh\",low_cpu_mem_usage=True,device_map=\"auto\",torch_dtype='auto')\n",
        "#low_cpu_mem_usage=True + 'torch_dtype'='auto'  会节省内存，注意low cpu mem 在ZeRO stage 3不能用\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Langboat/bloom-1b4-zh\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(example): #这次数据处理不进行batched，只处理单个的数据，因为label部分不太容易做\n",
        "  max_length=256\n",
        "  tokenized_input=tokenizer(\"\\n\".join([\"User:\"+example[\"instruction\"],example[\"input\"]]).strip()+\"\\nAssistant:\")\n",
        "  tokenized_output=tokenizer(example[\"output\"]+tokenizer.eos_token)\n",
        "  input_ids=tokenized_input[\"input_ids\"]+tokenized_output[\"input_ids\"]\n",
        "  attention_mask=tokenized_input[\"attention_mask\"]+tokenized_output[\"attention_mask\"]\n",
        "  labels= [-100]*len(tokenized_input[\"input_ids\"])+tokenized_output[\"input_ids\"]\n",
        "  if len(input_ids)>max_length:\n",
        "    input_ids=input_ids[:max_length]\n",
        "    attention_mask=attention_mask[:max_length]\n",
        "    labels=labels[:max_length]\n",
        "  return {\n",
        "      \"input_ids\":input_ids,\n",
        "      \"attention_mask\":attention_mask,\n",
        "      \"labels\":labels\n",
        "  }\n",
        "tokenized_ds=ds.map(data_process,remove_columns=ds[\"train\"].column_names)\n",
        "tokenized_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "93d4bb980f194c9ab907b9af379e34c0",
            "317cc2d1b61542c7bcc0386dac07084e",
            "6ecd5bad03a740939c69e42d62f7c10c",
            "d91dc6980dd34bfc92d7046376847e82",
            "918b3a416dc346b6af0ed4766a37ecf0",
            "4488ddabcc074e188585201dfafe912e",
            "61ef3249605144a282ad6bdfbeedef69",
            "9c3979bce8b645b8b612ba9c71124db0",
            "a43511eb5a1e4f0296f9dcd925da6ebd",
            "884ab3696039412db512fca7c58da1c9",
            "a4ea03018f4c47209c3dc74f60784b45"
          ]
        },
        "id": "shAVIK7ZwJlq",
        "outputId": "08aea98d-c5fa-4105-b0a6-f5d44ee19ba9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93d4bb980f194c9ab907b9af379e34c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TAJxOWt2q9o",
        "outputId": "c4a99a31-5f10-4ac3-d2ce-39aa5b8e6f4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BloomForCausalLM(\n",
              "  (transformer): BloomModel(\n",
              "    (word_embeddings): Embedding(46145, 2048)\n",
              "    (word_embeddings_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x BloomBlock(\n",
              "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): BloomAttention(\n",
              "          (query_key_value): Linear(in_features=2048, out_features=6144, bias=True)\n",
              "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): BloomMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "          (gelu_impl): BloomGelu()\n",
              "          (dense_4h_to_h): Linear(in_features=8192, out_features=2048, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=46145, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = IA3Config(task_type=TaskType.CAUSAL_LM)\n",
        "#target_modules一般来说是k,v 但是bloom比较特殊，qkv是一起的，所以这里针对bloom的话config里面target_modules就是qkv，feedforward_module就是ff\n",
        "#IA3是对K,V,FF，三部分的值进行调整（抑制或放大内部激活，通过可学习的向量对激活值进行抑制或者放大）\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6Gn4XU22cCw",
        "outputId": "2983c406-1d57-4959-9958-3a791672ddd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IA3Config(peft_type=<PeftType.IA3: 'IA3'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, target_modules=None, feedforward_modules=None, fan_in_fan_out=False, modules_to_save=None, init_ia3_weights=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, config)"
      ],
      "metadata": {
        "id": "XXeFkL_92mUv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model\n",
        "#query_key_value和dense_4h_to_h后面多了ia3_l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvid2KdA2sBo",
        "outputId": "86026e10-4d8a-49d2-8b25-35777deb4121"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): IA3Model(\n",
              "    (model): BloomForCausalLM(\n",
              "      (transformer): BloomModel(\n",
              "        (word_embeddings): Embedding(46145, 2048)\n",
              "        (word_embeddings_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (h): ModuleList(\n",
              "          (0-23): 24 x BloomBlock(\n",
              "            (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "            (self_attention): BloomAttention(\n",
              "              (query_key_value): Linear(\n",
              "                in_features=2048, out_features=6144, bias=True\n",
              "                (ia3_l): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 6144x1 (cuda:0)])\n",
              "              )\n",
              "              (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): BloomMLP(\n",
              "              (dense_h_to_4h): Linear(in_features=2048, out_features=8192, bias=True)\n",
              "              (gelu_impl): BloomGelu()\n",
              "              (dense_4h_to_h): Linear(\n",
              "                in_features=8192, out_features=2048, bias=True\n",
              "                (ia3_l): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 1x8192 (cuda:0)])\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=2048, out_features=46145, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrasfhWR2mt_",
        "outputId": "ff908949-d3a8-4881-80bc-34883dfb640d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IA3Config(peft_type=<PeftType.IA3: 'IA3'>, auto_mapping=None, base_model_name_or_path='Langboat/bloom-1b4-zh', revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, target_modules=['query_key_value', 'mlp.dense_4h_to_h'], feedforward_modules=['mlp.dense_4h_to_h'], fan_in_fan_out=False, modules_to_save=None, init_ia3_weights=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.print_trainable_parameters()\n",
        "#参与微调的参数很少，比Lora还少"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F2jdde050bg",
        "outputId": "e0c4f3a7-681e-468f-c6a0-f799742238a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 344,064 || all params: 1,303,455,744 || trainable%: 0.026396293206254036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# args = TrainingArguments(\n",
        "#     output_dir=\"./chatbot\",\n",
        "#     per_device_train_batch_size=1,\n",
        "#     gradient_accumulation_steps=8,\n",
        "#     logging_steps=10,\n",
        "#     num_train_epochs=1,\n",
        "#     learning_rate=3e-3\n",
        "# )"
      ],
      "metadata": {
        "id": "UPx5R6pl2u8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"./IA3\",\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    logging_steps=5,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=5,\n",
        "    learning_rate=3e-3 #官方推荐3e-3\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Mz5r5Bfj20nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"Langboat/bloom-1b4-zh\",low_cpu_mem_usage=True,torch_dtype='auto')\n",
        "p_model = PeftModel.from_pretrained(model, model_id=\"/content/drive/MyDrive/nlp/IA3/checkpoint-10\")\n",
        "model = p_model.cuda()\n",
        "ipt = tokenizer(\"Human: {}\\n{}\".format(\"考试有哪些技巧？\", \"\").strip() + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
        "tokenizer.decode(model.generate(**ipt)[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "i368L5_73AHA",
        "outputId": "b3112201-541e-441e-aa37-9b383ad67446"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: 考试有哪些技巧？\\n\\nAssistant: 考试技巧有很多，比如：\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ipt = tokenizer(\"Human: {}\\n{}\".format(\"考试有哪些技巧？\", \"\").strip() + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
        "tokenizer.decode(model.generate(**ipt,max_length=128,do_sample=True,repetition_penalty=1.3)[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ohQ_owjE7jfy",
        "outputId": "a0850b39-5c2e-4933-d4bb-7d2c798a5b29"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: 考试有哪些技巧？\\n\\nAssistant: 面试和考前计划对成功至关重要，在准备过程中应密切关注重要信息并确定主要内容。最重要的是找到自己的优势并为即将发生的冲突创建良好的情况模型。您还将学习必要的沟通礼仪并与他人进行有效的互动。\\n参加英语语言专业学位 (LLM)学生应该具有熟练的听、说及其它交流技能以及批判性思维能力和科学分析能力以便有效地与世界其他地方的人交谈并获得他人的尊重并在竞争激烈的工作环境中获得职业机会。\\n通过提供专门研究主题的特定课程来帮助您的教育项目保持竞争力并且培养更具相关性和创造'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generate(**ipt, max_length=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQuH_DHj6CQp",
        "outputId": "cfc0d007-dd5f-4689-e650-92e435994975"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[26283,    29,   210, 12913, 26620, 16012,  1518,   189,   189,  4340,\n",
              "         17245,    29,   210, 12913, 26620, 16012,  1518,   189,  4340, 17245,\n",
              "            29,   210, 12913, 26620, 16012,  1518,   189,  4340, 17245,    29,\n",
              "           210, 12913, 26620, 16012,  1518,   189,  4340, 17245,    29,   210,\n",
              "         12913, 26620, 16012,  1518,   189,  4340, 17245,    29,   210, 12913,\n",
              "         26620, 16012,  1518,   189,  4340, 17245,    29,   210, 12913, 26620,\n",
              "         16012,  1518,   189,  4340, 17245,    29,   210, 12913, 26620, 16012,\n",
              "          1518,   189,  4340, 17245,    29,   210, 12913, 26620, 16012,  1518,\n",
              "           189,  4340, 17245,    29,   210, 12913, 26620, 16012,  1518,   189,\n",
              "          4340, 17245,    29,   210, 12913, 26620, 16012,  1518,   189,  4340,\n",
              "         17245,    29,   210, 12913, 26620, 16012,  1518,   189,  4340, 17245,\n",
              "            29,   210, 12913, 26620, 16012,  1518,   189,  4340, 17245,    29,\n",
              "           210, 12913, 26620, 16012,  1518,   189,  4340, 17245]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIrMB_cd6D75"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}